{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyse the data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blues.00000.wav</td>\n",
       "      <td>0.349943</td>\n",
       "      <td>0.130225</td>\n",
       "      <td>1784.420446</td>\n",
       "      <td>2002.650192</td>\n",
       "      <td>3806.485316</td>\n",
       "      <td>0.083066</td>\n",
       "      <td>-113.596748</td>\n",
       "      <td>121.557297</td>\n",
       "      <td>-19.158825</td>\n",
       "      <td>...</td>\n",
       "      <td>8.810669</td>\n",
       "      <td>-3.667369</td>\n",
       "      <td>5.751690</td>\n",
       "      <td>-5.162763</td>\n",
       "      <td>0.750948</td>\n",
       "      <td>-1.691938</td>\n",
       "      <td>-0.409953</td>\n",
       "      <td>-2.300209</td>\n",
       "      <td>1.219929</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blues.00001.wav</td>\n",
       "      <td>0.340983</td>\n",
       "      <td>0.095918</td>\n",
       "      <td>1529.835316</td>\n",
       "      <td>2038.617579</td>\n",
       "      <td>3548.820207</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>-207.556793</td>\n",
       "      <td>124.006721</td>\n",
       "      <td>8.930560</td>\n",
       "      <td>...</td>\n",
       "      <td>5.376802</td>\n",
       "      <td>-2.239120</td>\n",
       "      <td>4.216963</td>\n",
       "      <td>-6.012273</td>\n",
       "      <td>0.936110</td>\n",
       "      <td>-0.716537</td>\n",
       "      <td>0.293876</td>\n",
       "      <td>-0.287431</td>\n",
       "      <td>0.531574</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blues.00002.wav</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>0.175573</td>\n",
       "      <td>1552.481958</td>\n",
       "      <td>1747.165985</td>\n",
       "      <td>3040.514948</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>-90.754387</td>\n",
       "      <td>140.459915</td>\n",
       "      <td>-29.109968</td>\n",
       "      <td>...</td>\n",
       "      <td>5.789265</td>\n",
       "      <td>-8.905224</td>\n",
       "      <td>-1.083720</td>\n",
       "      <td>-9.218360</td>\n",
       "      <td>2.455806</td>\n",
       "      <td>-7.726901</td>\n",
       "      <td>-1.815723</td>\n",
       "      <td>-3.433434</td>\n",
       "      <td>-2.226821</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blues.00003.wav</td>\n",
       "      <td>0.404779</td>\n",
       "      <td>0.141191</td>\n",
       "      <td>1070.119953</td>\n",
       "      <td>1596.333948</td>\n",
       "      <td>2185.028454</td>\n",
       "      <td>0.033309</td>\n",
       "      <td>-199.431152</td>\n",
       "      <td>150.099213</td>\n",
       "      <td>5.647593</td>\n",
       "      <td>...</td>\n",
       "      <td>6.087676</td>\n",
       "      <td>-2.476421</td>\n",
       "      <td>-1.073890</td>\n",
       "      <td>-2.874778</td>\n",
       "      <td>0.780977</td>\n",
       "      <td>-3.316932</td>\n",
       "      <td>0.637981</td>\n",
       "      <td>-0.619690</td>\n",
       "      <td>-3.408233</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blues.00004.wav</td>\n",
       "      <td>0.308590</td>\n",
       "      <td>0.091563</td>\n",
       "      <td>1835.494603</td>\n",
       "      <td>1748.362448</td>\n",
       "      <td>3580.945013</td>\n",
       "      <td>0.101500</td>\n",
       "      <td>-160.266037</td>\n",
       "      <td>126.198807</td>\n",
       "      <td>-35.605450</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.806384</td>\n",
       "      <td>-6.934123</td>\n",
       "      <td>-7.558618</td>\n",
       "      <td>-9.173553</td>\n",
       "      <td>-4.512165</td>\n",
       "      <td>-5.453538</td>\n",
       "      <td>-0.924161</td>\n",
       "      <td>-4.409333</td>\n",
       "      <td>-11.703781</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename  chroma_stft      rmse  spectral_centroid  \\\n",
       "0  blues.00000.wav     0.349943  0.130225        1784.420446   \n",
       "1  blues.00001.wav     0.340983  0.095918        1529.835316   \n",
       "2  blues.00002.wav     0.363603  0.175573        1552.481958   \n",
       "3  blues.00003.wav     0.404779  0.141191        1070.119953   \n",
       "4  blues.00004.wav     0.308590  0.091563        1835.494603   \n",
       "\n",
       "   spectral_bandwidth      rolloff  zero_crossing_rate       mfcc1  \\\n",
       "0         2002.650192  3806.485316            0.083066 -113.596748   \n",
       "1         2038.617579  3548.820207            0.056044 -207.556793   \n",
       "2         1747.165985  3040.514948            0.076301  -90.754387   \n",
       "3         1596.333948  2185.028454            0.033309 -199.431152   \n",
       "4         1748.362448  3580.945013            0.101500 -160.266037   \n",
       "\n",
       "        mfcc2      mfcc3  ...    mfcc12    mfcc13    mfcc14    mfcc15  \\\n",
       "0  121.557297 -19.158825  ...  8.810669 -3.667369  5.751690 -5.162763   \n",
       "1  124.006721   8.930560  ...  5.376802 -2.239120  4.216963 -6.012273   \n",
       "2  140.459915 -29.109968  ...  5.789265 -8.905224 -1.083720 -9.218360   \n",
       "3  150.099213   5.647593  ...  6.087676 -2.476421 -1.073890 -2.874778   \n",
       "4  126.198807 -35.605450  ... -2.806384 -6.934123 -7.558618 -9.173553   \n",
       "\n",
       "     mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  label  \n",
       "0  0.750948 -1.691938 -0.409953 -2.300209   1.219929  blues  \n",
       "1  0.936110 -0.716537  0.293876 -0.287431   0.531574  blues  \n",
       "2  2.455806 -7.726901 -1.815723 -3.433434  -2.226821  blues  \n",
       "3  0.780977 -3.316932  0.637981 -0.619690  -3.408233  blues  \n",
       "4 -4.512165 -5.453538 -0.924161 -4.409333 -11.703781  blues  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x254001db470>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "sns.catplot(y= 'label', kind= 'count', data= data, palette = 'pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 28)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['filename'], axis=1) # drop name of the column which is unnecessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "labels = data.iloc[:,-1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape\n",
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 13, 2, 1), (200, 13, 2, 1), (800,), (200,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping into 2d array\n",
    "train_x=np.reshape(train_x,(train_x.shape[0],13,2,1))\n",
    "test_x=np.reshape(test_x,(test_x.shape[0],13,2,1))\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "train_y=to_categorical(train_y, num_classes=10)\n",
    "test_y=to_categorical(test_y, num_classes=10)\n",
    "train_y.shape, test_y.shape\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "# import BatchNormalization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding layers and forming the model\n",
    "model.add(Conv2D(64,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\",input_shape=(13,2,1)))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "\n",
    "model.add(Conv2D(128,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256,kernel_size=5,strides=1,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(padding=\"same\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "# model.add(Dropout(0.35))\n",
    "\n",
    "model.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 2.3020 - accuracy: 0.1050 - val_loss: 2.2948 - val_accuracy: 0.2350\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 2.2760 - accuracy: 0.1500 - val_loss: 2.2264 - val_accuracy: 0.2100\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 2.1653 - accuracy: 0.2050 - val_loss: 2.0194 - val_accuracy: 0.2150\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.9600 - accuracy: 0.2637 - val_loss: 1.8053 - val_accuracy: 0.3500\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.8289 - accuracy: 0.2975 - val_loss: 1.7786 - val_accuracy: 0.3900\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.8055 - accuracy: 0.3125 - val_loss: 1.7175 - val_accuracy: 0.3900\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.7201 - accuracy: 0.3425 - val_loss: 1.6964 - val_accuracy: 0.4050\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.6772 - accuracy: 0.3587 - val_loss: 1.6209 - val_accuracy: 0.4300\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.6058 - accuracy: 0.3775 - val_loss: 1.6264 - val_accuracy: 0.4200\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.5997 - accuracy: 0.3925 - val_loss: 1.5525 - val_accuracy: 0.4000\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.5187 - accuracy: 0.4363 - val_loss: 1.5561 - val_accuracy: 0.4050\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.5182 - accuracy: 0.4175 - val_loss: 1.5340 - val_accuracy: 0.4700\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.5010 - accuracy: 0.4212 - val_loss: 1.5171 - val_accuracy: 0.4500\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.4796 - accuracy: 0.4400 - val_loss: 1.4710 - val_accuracy: 0.4950\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.4151 - accuracy: 0.4613 - val_loss: 1.4502 - val_accuracy: 0.4750\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.4427 - accuracy: 0.4462 - val_loss: 1.5000 - val_accuracy: 0.4550\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.4081 - accuracy: 0.4812 - val_loss: 1.4097 - val_accuracy: 0.5050\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.3745 - accuracy: 0.4787 - val_loss: 1.4156 - val_accuracy: 0.5250\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.3643 - accuracy: 0.4975 - val_loss: 1.4246 - val_accuracy: 0.5300\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.3489 - accuracy: 0.4913 - val_loss: 1.3748 - val_accuracy: 0.5050\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.2889 - accuracy: 0.5125 - val_loss: 1.3387 - val_accuracy: 0.5450\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.2573 - accuracy: 0.5450 - val_loss: 1.3240 - val_accuracy: 0.5400\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.2379 - accuracy: 0.5512 - val_loss: 1.3196 - val_accuracy: 0.5650\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.2247 - accuracy: 0.5625 - val_loss: 1.3040 - val_accuracy: 0.5600\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.2034 - accuracy: 0.5562 - val_loss: 1.2871 - val_accuracy: 0.5800\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.1687 - accuracy: 0.5825 - val_loss: 1.3150 - val_accuracy: 0.5750\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.1610 - accuracy: 0.5813 - val_loss: 1.2544 - val_accuracy: 0.5700\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.1127 - accuracy: 0.5975 - val_loss: 1.2746 - val_accuracy: 0.5650\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.0915 - accuracy: 0.6062 - val_loss: 1.2848 - val_accuracy: 0.5950\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.0509 - accuracy: 0.6225 - val_loss: 1.2604 - val_accuracy: 0.6050\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.0499 - accuracy: 0.6175 - val_loss: 1.2110 - val_accuracy: 0.5800\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 1.0061 - accuracy: 0.6375 - val_loss: 1.2411 - val_accuracy: 0.5500\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.9868 - accuracy: 0.6450 - val_loss: 1.2156 - val_accuracy: 0.5850\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.9437 - accuracy: 0.6637 - val_loss: 1.2684 - val_accuracy: 0.5750\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.9587 - accuracy: 0.6400 - val_loss: 1.1952 - val_accuracy: 0.6050\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8930 - accuracy: 0.6862 - val_loss: 1.2434 - val_accuracy: 0.5850\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8939 - accuracy: 0.6712 - val_loss: 1.2731 - val_accuracy: 0.5650\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8605 - accuracy: 0.6837 - val_loss: 1.3485 - val_accuracy: 0.5650\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.8879 - accuracy: 0.6825 - val_loss: 1.1807 - val_accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7965 - accuracy: 0.7150 - val_loss: 1.2318 - val_accuracy: 0.6150\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7625 - accuracy: 0.7275 - val_loss: 1.2593 - val_accuracy: 0.6100\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7887 - accuracy: 0.7200 - val_loss: 1.2377 - val_accuracy: 0.5800\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7664 - accuracy: 0.7163 - val_loss: 1.2239 - val_accuracy: 0.5800\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.7356 - accuracy: 0.7375 - val_loss: 1.2645 - val_accuracy: 0.5750\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6879 - accuracy: 0.7487 - val_loss: 1.2397 - val_accuracy: 0.5700\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6920 - accuracy: 0.7700 - val_loss: 1.2421 - val_accuracy: 0.5800\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6694 - accuracy: 0.7675 - val_loss: 1.2984 - val_accuracy: 0.5850\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6560 - accuracy: 0.7638 - val_loss: 1.2624 - val_accuracy: 0.5550\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6103 - accuracy: 0.7862 - val_loss: 1.2832 - val_accuracy: 0.5700\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6271 - accuracy: 0.7788 - val_loss: 1.3353 - val_accuracy: 0.5750\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6252 - accuracy: 0.7750 - val_loss: 1.2824 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.6299 - accuracy: 0.7862 - val_loss: 1.2716 - val_accuracy: 0.5800\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5784 - accuracy: 0.7950 - val_loss: 1.2638 - val_accuracy: 0.5850\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5896 - accuracy: 0.7850 - val_loss: 1.2847 - val_accuracy: 0.6100\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5825 - accuracy: 0.7925 - val_loss: 1.2721 - val_accuracy: 0.5950\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5589 - accuracy: 0.8037 - val_loss: 1.2815 - val_accuracy: 0.6200\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5297 - accuracy: 0.8125 - val_loss: 1.2252 - val_accuracy: 0.6100\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4661 - accuracy: 0.8450 - val_loss: 1.3774 - val_accuracy: 0.5800\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5035 - accuracy: 0.8213 - val_loss: 1.3578 - val_accuracy: 0.5650\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4798 - accuracy: 0.8138 - val_loss: 1.3947 - val_accuracy: 0.5900\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4695 - accuracy: 0.8425 - val_loss: 1.3177 - val_accuracy: 0.5600\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4434 - accuracy: 0.8363 - val_loss: 1.3980 - val_accuracy: 0.6000\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.8062 - val_loss: 1.2371 - val_accuracy: 0.5700\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4859 - accuracy: 0.8100 - val_loss: 1.2947 - val_accuracy: 0.6100\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4850 - accuracy: 0.8413 - val_loss: 1.2916 - val_accuracy: 0.5850\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4640 - accuracy: 0.8512 - val_loss: 1.2157 - val_accuracy: 0.6100\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3979 - accuracy: 0.8675 - val_loss: 1.4665 - val_accuracy: 0.5900\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.4131 - accuracy: 0.8537 - val_loss: 1.3426 - val_accuracy: 0.5850\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3404 - accuracy: 0.8838 - val_loss: 1.4673 - val_accuracy: 0.6000\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3362 - accuracy: 0.8712 - val_loss: 1.4420 - val_accuracy: 0.6050\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3163 - accuracy: 0.8950 - val_loss: 1.5715 - val_accuracy: 0.5850\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3100 - accuracy: 0.8838 - val_loss: 1.3891 - val_accuracy: 0.5900\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3289 - accuracy: 0.8913 - val_loss: 1.4543 - val_accuracy: 0.5900\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3082 - accuracy: 0.8875 - val_loss: 1.4572 - val_accuracy: 0.6300\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2742 - accuracy: 0.8988 - val_loss: 1.4648 - val_accuracy: 0.6050\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2874 - accuracy: 0.9062 - val_loss: 1.3926 - val_accuracy: 0.6350\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2891 - accuracy: 0.8963 - val_loss: 1.4915 - val_accuracy: 0.5950\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.3235 - accuracy: 0.8838 - val_loss: 1.4171 - val_accuracy: 0.6150\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.8988 - val_loss: 1.4830 - val_accuracy: 0.5950\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2784 - accuracy: 0.9075 - val_loss: 1.3785 - val_accuracy: 0.6150\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2348 - accuracy: 0.9225 - val_loss: 1.4111 - val_accuracy: 0.6150\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2411 - accuracy: 0.9212 - val_loss: 1.4943 - val_accuracy: 0.6200\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2188 - accuracy: 0.9337 - val_loss: 1.4517 - val_accuracy: 0.6250\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2093 - accuracy: 0.9350 - val_loss: 1.5476 - val_accuracy: 0.5900\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2297 - accuracy: 0.9225 - val_loss: 1.6811 - val_accuracy: 0.5850\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2712 - accuracy: 0.9125 - val_loss: 1.5794 - val_accuracy: 0.5850\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2418 - accuracy: 0.9125 - val_loss: 1.5626 - val_accuracy: 0.6150\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2626 - accuracy: 0.9087 - val_loss: 1.5052 - val_accuracy: 0.5900\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2459 - accuracy: 0.9212 - val_loss: 1.5241 - val_accuracy: 0.6100\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2203 - accuracy: 0.9312 - val_loss: 1.5599 - val_accuracy: 0.5950\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2137 - accuracy: 0.9100 - val_loss: 1.5991 - val_accuracy: 0.6200\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2148 - accuracy: 0.9150 - val_loss: 1.5734 - val_accuracy: 0.5900\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2339 - accuracy: 0.9175 - val_loss: 1.5557 - val_accuracy: 0.5850\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1904 - accuracy: 0.9325 - val_loss: 1.5520 - val_accuracy: 0.5850\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1648 - accuracy: 0.9413 - val_loss: 1.7705 - val_accuracy: 0.5950\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2000 - accuracy: 0.9312 - val_loss: 1.6390 - val_accuracy: 0.6000\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1856 - accuracy: 0.9350 - val_loss: 1.8579 - val_accuracy: 0.5700\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.2138 - accuracy: 0.9262 - val_loss: 1.7926 - val_accuracy: 0.5850\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1980 - accuracy: 0.9325 - val_loss: 1.7753 - val_accuracy: 0.6050\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 1s 1ms/step - loss: 0.1785 - accuracy: 0.9388 - val_loss: 1.7016 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25403128f60>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "model.fit(train_x,train_y,batch_size=128,epochs=100,validation_data=(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
